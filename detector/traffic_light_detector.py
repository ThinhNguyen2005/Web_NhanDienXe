"""
Module chuyÃªn xá»­ lÃ½ phÃ¡t hiá»‡n Ä‘Ã¨n tÃ­n hiá»‡u giao thÃ´ng.
Sá»­ dá»¥ng YOLOv8 (qua thÆ° viá»‡n ultralytics) Ä‘á»ƒ phÃ¡t hiá»‡n Ä‘Ã¨n giao thÃ´ng,
sau Ä‘Ã³ phÃ¢n loáº¡i mÃ u (Ä‘á» / vÃ ng / xanh) báº±ng hÃ m estimate_label.
CÃ¡ch nÃ y tÆ°Æ¡ng thÃ­ch tá»‘t hÆ¡n vá»›i mÃ´i trÆ°á»ng dá»± Ã¡n hiá»‡n táº¡i.
"""
import cv2
import numpy as np
from ultralytics import YOLO
import os

# Sá»­ dá»¥ng YOLOv8n, má»™t model nháº¹ vÃ  nhanh phÃ¹ há»£p cho viá»‡c phÃ¡t hiá»‡n Ä‘Ã¨n
PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
_model = YOLO(os.path.join(PROJECT_DIR, "yolov8n.pt"))
# Lá»›p 9 trong COCO dataset lÃ  'traffic light'
TRAFFIC_LIGHT_CLASS_ID = 9


def create_feature(rgb_image):
  '''Basic brightness feature, required by Udacity'''
  hsv = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV) # Convert to HSV color space

  sum_brightness = np.sum(hsv[:,:,2]) # Sum the brightness values
  area = 32*32
  avg_brightness = sum_brightness / area # Find the average

  return avg_brightness

def high_saturation_pixels(rgb_image, threshold):
  '''Returns average red and green content from high saturation pixels'''
  high_sat_pixels = []
  hsv = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)
  for i in range(32):
    for j in range(32):
      if hsv[i][j][1] > threshold:
        high_sat_pixels.append(rgb_image[i][j])

  if not high_sat_pixels:
    return highest_sat_pixel(rgb_image)

  sum_red = 0
  sum_green = 0
  for pixel in high_sat_pixels:
    sum_red += pixel[0]
    sum_green += pixel[1]

  # TODO: Use sum() instead of manually adding them up
  avg_red = sum_red / len(high_sat_pixels)
  avg_green = sum_green / len(high_sat_pixels) * 0.8 # 0.8 to favor red's chances
  return avg_red, avg_green

def highest_sat_pixel(rgb_image):
  '''Finds the higest saturation pixel, and checks if it has a higher green
  content, or a higher red content'''

  hsv = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)
  s = hsv[:,:,1]

  x, y = (np.unravel_index(np.argmax(s), s.shape))
  if rgb_image[x, y, 0] > rgb_image[x,y, 1] * 0.9: # 0.9 to favor red's chances
    return 1, 0 # Red has a higher content
  return 0, 1



def findNonZero(rgb_image):
  rows, cols, _ = rgb_image.shape
  counter = 0

  for row in range(rows):
    for col in range(cols):
      pixel = rgb_image[row, col]
      if sum(pixel) != 0:
        counter = counter + 1

  return counter

def red_green_yellow(rgb_image):
    """
    PhÃ¢n tÃ­ch má»™t áº£nh RGB Ä‘Ã£ Ä‘Æ°á»£c crop cá»§a Ä‘Ã¨n giao thÃ´ng vÃ  tráº£ vá» mÃ u sáº¯c.
    PhiÃªn báº£n nÃ y Ä‘Ã£ Ä‘Æ°á»£c sá»­a lá»—i trÃ n sá»‘ (overflow).

    Args:
        rgb_image: áº¢nh crop cá»§a Ä‘Ã¨n giao thÃ´ng (Ä‘á»‹nh dáº¡ng RGB).

    Returns:
        str: "red", "green", "yellow", hoáº·c "unknown".
    """
    if rgb_image is None or rgb_image.size == 0:
        return "unknown"

    # Chuyá»ƒn áº£nh sang khÃ´ng gian mÃ u HSV Ä‘á»ƒ dá»… dÃ ng phÃ¢n tÃ­ch mÃ u sáº¯c
    hsv = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)

    # --- Äá»‹nh nghÄ©a cÃ¡c dáº£i mÃ u trong khÃ´ng gian HSV ---

    # Dáº£i mÃ u Äá»Ž (cÃ³ thá»ƒ gá»“m 2 khoáº£ng do mÃ u Ä‘á» náº±m á»Ÿ 2 Ä‘áº§u cá»§a phá»• mÃ u HSV)
    lower_red1 = np.array([0, 70, 50])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([170, 70, 50])
    upper_red2 = np.array([180, 255, 255])

    # Dáº£i mÃ u VÃ€NG
    lower_yellow = np.array([20, 100, 100])
    upper_yellow = np.array([30, 255, 255])

    # Dáº£i mÃ u XANH
    lower_green = np.array([40, 40, 40])
    upper_green = np.array([90, 255, 255])

    # --- Táº¡o mask Ä‘á»ƒ lá»c cÃ¡c pixel thuá»™c dáº£i mÃ u tÆ°Æ¡ng á»©ng ---
    mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask_red = cv2.add(mask_red1, mask_red2) # Káº¿t há»£p 2 mask Ä‘á»

    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)
    mask_green = cv2.inRange(hsv, lower_green, upper_green)

    # --- Äáº¿m sá»‘ lÆ°á»£ng pixel khÃ¡c khÃ´ng trong má»—i mask ---
    # ÄÃ¢y lÃ  cÃ¡ch hiá»‡u quáº£ vÃ  an toÃ n, khÃ´ng gÃ¢y ra lá»—i trÃ n sá»‘
    red_pixels = np.count_nonzero(mask_red)
    yellow_pixels = np.count_nonzero(mask_yellow)
    green_pixels = np.count_nonzero(mask_green)

    # Táº¡o má»™t dictionary Ä‘á»ƒ dá»… dÃ ng tÃ¬m ra mÃ u cÃ³ nhiá»u pixel nháº¥t
    colors = {
        "red": red_pixels,
        "yellow": yellow_pixels,
        "green": green_pixels
    }

    # Äáº·t má»™t ngÆ°á»¡ng tá»‘i thiá»ƒu Ä‘á»ƒ trÃ¡nh nháº­n diá»‡n nhiá»…u
    # VÃ­ dá»¥: pháº£i cÃ³ Ã­t nháº¥t 5% tá»•ng sá»‘ pixel lÃ  má»™t mÃ u nÃ o Ä‘Ã³ má»›i tÃ­nh
    min_pixel_threshold = (rgb_image.shape[0] * rgb_image.shape[1]) * 0.05

    # Lá»c ra cÃ¡c mÃ u vÆ°á»£t ngÆ°á»¡ng
    valid_colors = {color: count for color, count in colors.items() if count > min_pixel_threshold}

    if not valid_colors:
        return "unknown"

    # Tráº£ vá» mÃ u cÃ³ sá»‘ lÆ°á»£ng pixel lá»›n nháº¥t
    return max(valid_colors, key=valid_colors.get)


def estimate_label(rgb_image):
    """
    HÃ m chÃ­nh Ä‘á»ƒ Æ°á»›c tÃ­nh mÃ u Ä‘Ã¨n. Gá»i hÃ m red_green_yellow Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u.
    """
    return red_green_yellow(rgb_image)

def _classify_light_color(bgr_roi):
    """PhÃ¢n loáº¡i mÃ u Ä‘Ã¨n tá»« ROI BGR -> tráº£ vá» 'red' | 'yellow' | 'green' | 'unknown'."""
    if bgr_roi is None or bgr_roi.size == 0:
        return "unknown"
    try:
        # Chuáº©n hÃ³a vá» 32x32 vÃ  chuyá»ƒn sang RGB cho bá»™ phÃ¢n loáº¡i mÃ u
        roi_resized = cv2.resize(bgr_roi, (32, 32), interpolation=cv2.INTER_AREA)
        rgb_roi = cv2.cvtColor(roi_resized, cv2.COLOR_BGR2RGB)
        color = estimate_label(rgb_roi)
        return color if color in ("red", "yellow", "green") else "unknown"
    except Exception:
        return "unknown"

def detect_traffic_lights_with_color(frame, conf_thresh=0.4):
    """
    PhÃ¡t hiá»‡n Ä‘Ã¨n giao thÃ´ng báº±ng YOLOv8 vÃ  phÃ¢n loáº¡i mÃ u.
    Tráº£ vá» danh sÃ¡ch dict: { 'bbox': (x,y,w,h), 'color': 'red|yellow|green|unknown', 'conf': float }.
    """
    results = _model(frame, classes=[TRAFFIC_LIGHT_CLASS_ID], verbose=False)
    detections = []
    if results:
        for r in results:
            for box in r.boxes:
                if box.conf and box.conf[0] > conf_thresh:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    w, h = x2 - x1, y2 - y1
                    roi = frame[y1:y2, x1:x2]
                    color = _classify_light_color(roi)
                    detections.append({
                        'bbox': (x1, y1, w, h),
                        'color': color,
                        'conf': float(box.conf[0])
                    })
    return detections

def detect_stop_line(frame, roi_height_ratio=0.25, white_thresh_v=200,
                     canny_thresh1=50, canny_thresh2=150,
                     min_line_length_ratio=0.4, max_line_gap=20,
                     slope_thresh=0.2):
    """
    Detect a horizontal white stop line on the road and return its y-coordinate (int).

    Enhanced Strategy:
    - Convert to HSV and threshold bright/white pixels (low saturation, high value).
    - Apply morphological operations to clean the mask
    - Restrict search to the lower part of the frame (configurable by roi_height_ratio).
    - Run Canny edge detector and HoughLinesP to find long horizontal segments.
    - Filter lines by slope (near-horizontal) and choose the one nearest to the bottom
      (largest y) or the longest one.

    Returns:
        int or None: y-coordinate in full-frame coordinates, or None if not found.
    """
    if frame is None or frame.size == 0:
        return None

    h, w = frame.shape[:2]
    
    # Convert to HSV and threshold for white/bright pixels
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    lower_white = np.array([0, 0, white_thresh_v])
    upper_white = np.array([180, 60, 255])
    mask = cv2.inRange(hsv, lower_white, upper_white)

    # Apply morphological operations to clean the mask
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)

    # Restrict to lower ROI where stop line usually appears
    roi_y = int(h * (1.0 - roi_height_ratio))
    roi = mask[roi_y:h, :]

    # Edge detection with improved parameters
    blurred = cv2.GaussianBlur(roi, (5, 5), 0)
    edges = cv2.Canny(blurred, canny_thresh1, canny_thresh2)

    # Hough transform to detect lines
    min_line_length = int(w * min_line_length_ratio)
    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=50,
                            minLineLength=min_line_length, maxLineGap=max_line_gap)

    if lines is None:
        return None

    candidate_lines = []
    for x1, y1, x2, y2 in lines.reshape(-1, 4):
        dx = x2 - x1
        dy = y2 - y1
        if dx == 0:
            continue
        slope = abs(dy / float(dx))
        length = np.hypot(dx, dy)
        
        # More strict filtering for horizontal lines
        if slope <= slope_thresh and length >= min_line_length:
            # Check if line spans significant portion of width
            line_width = abs(x2 - x1)
            if line_width >= w * 0.3:  # Line should span at least 30% of frame width
                # map y back to full-frame coordinates (use average y of the segment)
                avg_y = int((y1 + y2) / 2) + roi_y
                candidate_lines.append((avg_y, length, line_width))

    if not candidate_lines:
        return None

    # Prefer the line closest to bottom (largest y), then by width, then by length
    candidate_lines.sort(key=lambda t: (t[0], t[2], t[1]), reverse=True)
    chosen_y = candidate_lines[0][0]
    return chosen_y

def detect_traffic_lights(frame):
    """
    HÃ m tÆ°Æ¡ng thÃ­ch ngÆ°á»£c, chá»‰ phÃ¡t hiá»‡n vÃ  tráº£ vá» bbox cá»§a Ä‘Ã¨n giao thÃ´ng.
    """
    detections = detect_traffic_lights_with_color(frame)
    return [d['bbox'] for d in detections]

def draw_traffic_lights(frame, detections):
    """
    Váº½ khung vÃ  nhÃ£n mÃ u cho cÃ¡c Ä‘Ã¨n tÃ­n hiá»‡u Ä‘Ã£ phÃ¡t hiá»‡n.
    Tá»‘i Æ°u hÃ³a: Khung Ä‘áº¹p hÆ¡n, mÃ u sáº¯c rÃµ rÃ ng, nhÃ£n thÃ´ng tin Ä‘áº§y Ä‘á»§.
    """
    # Báº£ng mÃ u BGR tá»‘i Æ°u cho Ä‘Ã¨n giao thÃ´ng
    color_map = {
        'red': (0, 0, 255),      # Äá» Ä‘áº­m
        'yellow': (0, 255, 255), # VÃ ng sÃ¡ng
        'green': (0, 255, 0),    # Xanh lÃ¡
        'unknown': (128, 128, 128) # XÃ¡m cho unknown
    }
    
    # MÃ u ná»n cho nhÃ£n (Ä‘á»ƒ dá»… Ä‘á»c)
    label_bg_colors = {
        'red': (0, 0, 200),
        'yellow': (0, 200, 200),
        'green': (0, 200, 0),
        'unknown': (100, 100, 100)
    }
    
    for i, d in enumerate(detections):
        x, y, w, h = d['bbox']
        color_name = d.get('color', 'unknown')
        confidence = d.get('conf', 0.0)
        
        # MÃ u khung chÃ­nh
        bgr_color = color_map.get(color_name, (128, 128, 128))
        bg_color = label_bg_colors.get(color_name, (100, 100, 100))
        
        # Váº½ khung chÃ­nh vá»›i Ä‘á»™ dÃ y tÃ¹y theo confidence
        thickness = 3 if confidence > 0.7 else 2
        cv2.rectangle(frame, (x, y), (x + w, y + h), bgr_color, thickness)
        
        # Váº½ khung phá»¥ bÃªn trong (táº¡o hiá»‡u á»©ng Ä‘áº¹p)
        inner_margin = 2
        cv2.rectangle(frame, 
                     (x + inner_margin, y + inner_margin), 
                     (x + w - inner_margin, y + h - inner_margin), 
                     bgr_color, 1)
        
        # Táº¡o nhÃ£n vá»›i background
        label_text = f"ðŸš¦ {color_name.upper()}"
        confidence_text = f"{confidence:.2f}"
        
        # Font settings
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        font_thickness = 2
        
        # TÃ­nh kÃ­ch thÆ°á»›c text
        (text_w, text_h), _ = cv2.getTextSize(label_text, font, font_scale, font_thickness)
        (conf_w, conf_h), _ = cv2.getTextSize(confidence_text, font, font_scale - 0.1, font_thickness - 1)
        
        # Vá»‹ trÃ­ nhÃ£n (phÃ­a trÃªn khung)
        label_x = x
        label_y = max(y - 10, text_h + 5)
        
        # Váº½ background cho nhÃ£n
        padding = 5
        cv2.rectangle(frame,
                     (label_x - padding, label_y - text_h - padding),
                     (label_x + max(text_w, conf_w) + padding, label_y + padding),
                     bg_color, -1)
        
        # Váº½ text chÃ­nh
        cv2.putText(frame, label_text, (label_x, label_y), 
                   font, font_scale, (255, 255, 255), font_thickness)
        
        # Váº½ confidence (náº¿u cÃ³)
        if confidence > 0:
            conf_y = label_y + conf_h + 2
            cv2.putText(frame, confidence_text, (label_x, conf_y), 
                       font, font_scale - 0.1, (200, 200, 200), font_thickness - 1)
    
    return frame

